{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Cell Analysis Data Visualization\n",
    "\n",
    "This notebook creates visualizations from single cell analysis data summarized in a CSV file where columns represent features and rows represent cells/objects.\n",
    "\n",
    "**Visualizations included:**\n",
    "1. Feature distributions (histograms, violin plots, box plots)\n",
    "2. Correlation heatmaps\n",
    "3. Clustered heatmaps (cells × features)\n",
    "4. Dimensionality reduction (PCA, UMAP, t-SNE)\n",
    "5. Spatial scatter plots\n",
    "6. Cluster summary plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from typing import List, Optional, Literal\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Optional imports\n",
    "try:\n",
    "    import umap\n",
    "    UMAP_AVAILABLE = True\n",
    "except ImportError:\n",
    "    UMAP_AVAILABLE = False\n",
    "    print(\"UMAP not available. Install with: pip install umap-learn\")\n",
    "\n",
    "try:\n",
    "    from sklearn.manifold import TSNE\n",
    "    TSNE_AVAILABLE = True\n",
    "except ImportError:\n",
    "    TSNE_AVAILABLE = False\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style(\"whitegrid\")\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.dpi'] = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration\n",
    "\n",
    "Set your input file path and parameters below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# USER CONFIGURATION - Modify these parameters\n",
    "# =============================================================================\n",
    "\n",
    "# Path to your cell table CSV file\n",
    "INPUT_CSV = \"path/to/your/cell_table.csv\"\n",
    "\n",
    "# Output directory for saving plots (set to None to skip saving)\n",
    "OUTPUT_DIR = \"./cell_visualizations\"\n",
    "\n",
    "# Column names (set to None for auto-detection)\n",
    "CLUSTER_COL = None          # e.g., \"cell_meta_cluster\", \"cluster\", \"phenotype\"\n",
    "CELL_ID_COL = None          # e.g., \"label\", \"cell_id\"\n",
    "X_COORD_COL = None          # e.g., \"centroid-0\", \"x\"\n",
    "Y_COORD_COL = None          # e.g., \"centroid-1\", \"y\"\n",
    "\n",
    "# Visualization parameters\n",
    "DPI = 150                   # Resolution for saved figures\n",
    "MAX_FEATURES = 20           # Max features to show in distribution plots\n",
    "SAMPLE_CELLS = 2000         # Max cells to sample for clustermaps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "print(f\"Loading data from: {INPUT_CSV}\")\n",
    "data = pd.read_csv(INPUT_CSV)\n",
    "\n",
    "print(f\"\\nDataset shape: {data.shape[0]} cells × {data.shape[1]} columns\")\n",
    "print(f\"\\nColumn names:\")\n",
    "for i, col in enumerate(data.columns):\n",
    "    print(f\"  {i+1:3d}. {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the data\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Auto-detect Feature Columns\n",
    "\n",
    "Automatically identifies numeric columns that are likely features (not metadata like cell IDs, coordinates, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_feature_columns(df: pd.DataFrame) -> List[str]:\n",
    "    \"\"\"Detect numeric columns that are likely features (not metadata).\"\"\"\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    \n",
    "    # Exclude common metadata columns\n",
    "    metadata_patterns = [\n",
    "        'label', 'id', 'fov', 'centroid', 'cell_size', 'area',\n",
    "        'index', 'row', 'col', 'x', 'y', 'cluster'\n",
    "    ]\n",
    "    \n",
    "    feature_cols = []\n",
    "    for col in numeric_cols:\n",
    "        col_lower = col.lower()\n",
    "        is_metadata = any(pattern in col_lower for pattern in metadata_patterns)\n",
    "        if not is_metadata:\n",
    "            feature_cols.append(col)\n",
    "    \n",
    "    # If we filtered too aggressively, include all numeric columns\n",
    "    if len(feature_cols) < 3:\n",
    "        feature_cols = numeric_cols\n",
    "    \n",
    "    return feature_cols\n",
    "\n",
    "# Detect features\n",
    "feature_cols = detect_feature_columns(data)\n",
    "print(f\"Detected {len(feature_cols)} feature columns:\")\n",
    "for col in feature_cols:\n",
    "    print(f\"  - {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto-detect spatial columns if not specified\n",
    "if X_COORD_COL is None or Y_COORD_COL is None:\n",
    "    spatial_candidates = [\n",
    "        ('centroid-0', 'centroid-1'),\n",
    "        ('centroid_x', 'centroid_y'),\n",
    "        ('x', 'y'),\n",
    "        ('X', 'Y'),\n",
    "    ]\n",
    "    for x_col, y_col in spatial_candidates:\n",
    "        if x_col in data.columns and y_col in data.columns:\n",
    "            X_COORD_COL, Y_COORD_COL = x_col, y_col\n",
    "            break\n",
    "\n",
    "if X_COORD_COL and Y_COORD_COL:\n",
    "    print(f\"Spatial columns: {X_COORD_COL}, {Y_COORD_COL}\")\n",
    "else:\n",
    "    print(\"No spatial columns detected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory if saving plots\n",
    "if OUTPUT_DIR:\n",
    "    Path(OUTPUT_DIR).mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"Output directory: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Feature Distributions\n",
    "\n",
    "Visualize the distribution of each feature across all cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_distributions(\n",
    "    df: pd.DataFrame,\n",
    "    features: List[str],\n",
    "    plot_type: Literal[\"histogram\", \"violin\", \"box\"] = \"histogram\",\n",
    "    ncols: int = 4,\n",
    "    figsize: Optional[tuple] = None,\n",
    ") -> plt.Figure:\n",
    "    \"\"\"Plot distributions of selected features.\"\"\"\n",
    "    features = features[:MAX_FEATURES]  # Limit number of features\n",
    "    nrows = int(np.ceil(len(features) / ncols))\n",
    "    \n",
    "    if figsize is None:\n",
    "        figsize = (ncols * 3, nrows * 2.5)\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=figsize)\n",
    "    axes = np.array(axes).flatten()\n",
    "    \n",
    "    for idx, feature in enumerate(tqdm(features, desc=\"Plotting\")):\n",
    "        ax = axes[idx]\n",
    "        feature_data = df[feature].dropna()\n",
    "        \n",
    "        if plot_type == \"histogram\":\n",
    "            ax.hist(feature_data, bins=50, edgecolor='black', alpha=0.7)\n",
    "        elif plot_type == \"violin\":\n",
    "            sns.violinplot(y=feature_data, ax=ax)\n",
    "        elif plot_type == \"box\":\n",
    "            sns.boxplot(y=feature_data, ax=ax)\n",
    "        \n",
    "        ax.set_title(feature, fontsize=10)\n",
    "        ax.tick_params(labelsize=8)\n",
    "    \n",
    "    # Hide empty subplots\n",
    "    for idx in range(len(features), len(axes)):\n",
    "        axes[idx].set_visible(False)\n",
    "    \n",
    "    plt.suptitle(\"Feature Distributions\", fontsize=14, y=1.02)\n",
    "    plt.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histograms\n",
    "fig = plot_feature_distributions(data, feature_cols, plot_type=\"histogram\")\n",
    "\n",
    "if OUTPUT_DIR:\n",
    "    fig.savefig(f\"{OUTPUT_DIR}/feature_distributions.png\", dpi=DPI, bbox_inches='tight')\n",
    "    print(f\"Saved: {OUTPUT_DIR}/feature_distributions.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Plot as violin plots\n",
    "# fig = plot_feature_distributions(data, feature_cols[:12], plot_type=\"violin\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Correlation Heatmap\n",
    "\n",
    "Visualize correlations between features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_correlation_heatmap(\n",
    "    df: pd.DataFrame,\n",
    "    features: List[str],\n",
    "    method: Literal[\"pearson\", \"spearman\", \"kendall\"] = \"pearson\",\n",
    "    figsize: Optional[tuple] = None,\n",
    "    cmap: str = \"RdBu_r\",\n",
    ") -> plt.Figure:\n",
    "    \"\"\"Plot correlation heatmap of features.\"\"\"\n",
    "    features = features[:30]  # Limit for readability\n",
    "    corr_matrix = df[features].corr(method=method)\n",
    "    \n",
    "    if figsize is None:\n",
    "        size = max(8, len(features) * 0.4)\n",
    "        figsize = (size, size)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    \n",
    "    sns.heatmap(\n",
    "        corr_matrix,\n",
    "        annot=len(features) <= 15,\n",
    "        fmt=\".2f\",\n",
    "        cmap=cmap,\n",
    "        center=0,\n",
    "        vmin=-1,\n",
    "        vmax=1,\n",
    "        square=True,\n",
    "        ax=ax,\n",
    "        cbar_kws={\"shrink\": 0.8}\n",
    "    )\n",
    "    \n",
    "    ax.set_title(f\"Feature Correlation ({method.capitalize()})\", fontsize=14)\n",
    "    plt.xticks(rotation=45, ha='right', fontsize=8)\n",
    "    plt.yticks(fontsize=8)\n",
    "    plt.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_correlation_heatmap(data, feature_cols, method=\"pearson\")\n",
    "\n",
    "if OUTPUT_DIR:\n",
    "    fig.savefig(f\"{OUTPUT_DIR}/correlation_heatmap.png\", dpi=DPI, bbox_inches='tight')\n",
    "    print(f\"Saved: {OUTPUT_DIR}/correlation_heatmap.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Clustered Heatmap (Clustermap)\n",
    "\n",
    "Hierarchically clustered heatmap showing cells vs features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_clustermap(\n",
    "    df: pd.DataFrame,\n",
    "    features: List[str],\n",
    "    n_cells: int = 1000,\n",
    "    standardize: bool = True,\n",
    "    figsize: tuple = (12, 10),\n",
    "    cmap: str = \"viridis\",\n",
    ") -> sns.matrix.ClusterGrid:\n",
    "    \"\"\"Plot clustered heatmap of cells vs features.\"\"\"\n",
    "    features = features[:30]\n",
    "    \n",
    "    # Sample cells if dataset is large\n",
    "    if len(df) > n_cells:\n",
    "        sample_data = df[features].sample(n=n_cells, random_state=42)\n",
    "        print(f\"Sampled {n_cells} cells from {len(df)} total\")\n",
    "    else:\n",
    "        sample_data = df[features]\n",
    "    \n",
    "    # Standardize if requested\n",
    "    if standardize:\n",
    "        scaler = StandardScaler()\n",
    "        plot_data = pd.DataFrame(\n",
    "            scaler.fit_transform(sample_data),\n",
    "            columns=features,\n",
    "            index=sample_data.index\n",
    "        )\n",
    "    else:\n",
    "        plot_data = sample_data\n",
    "    \n",
    "    g = sns.clustermap(\n",
    "        plot_data,\n",
    "        cmap=cmap,\n",
    "        figsize=figsize,\n",
    "        xticklabels=True,\n",
    "        yticklabels=False,\n",
    "        dendrogram_ratio=(0.1, 0.15),\n",
    "        cbar_pos=(0.02, 0.8, 0.03, 0.15),\n",
    "    )\n",
    "    \n",
    "    g.ax_heatmap.set_xlabel(\"Features\", fontsize=12)\n",
    "    g.ax_heatmap.set_ylabel(f\"Cells (n={len(plot_data)})\", fontsize=12)\n",
    "    plt.setp(g.ax_heatmap.get_xticklabels(), rotation=45, ha='right', fontsize=8)\n",
    "    \n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = plot_clustermap(data, feature_cols, n_cells=SAMPLE_CELLS)\n",
    "\n",
    "if OUTPUT_DIR:\n",
    "    g.savefig(f\"{OUTPUT_DIR}/clustermap.png\", dpi=DPI, bbox_inches='tight')\n",
    "    print(f\"Saved: {OUTPUT_DIR}/clustermap.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Dimensionality Reduction (PCA, UMAP, t-SNE)\n",
    "\n",
    "Reduce high-dimensional feature space to 2D for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dimensionality_reduction(\n",
    "    df: pd.DataFrame,\n",
    "    features: List[str],\n",
    "    method: Literal[\"pca\", \"umap\", \"tsne\"] = \"pca\",\n",
    "    color_by: Optional[str] = None,\n",
    "    n_components: int = 2,\n",
    "    figsize: tuple = (10, 8),\n",
    "    cmap: str = \"tab20\",\n",
    "    alpha: float = 0.6,\n",
    "    point_size: int = 10,\n",
    "    **kwargs,\n",
    ") -> plt.Figure:\n",
    "    \"\"\"Plot dimensionality reduction visualization.\"\"\"\n",
    "    # Prepare data\n",
    "    X = df[features].dropna()\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    print(f\"Running {method.upper()} on {len(X)} cells with {len(features)} features...\")\n",
    "    \n",
    "    # Apply dimensionality reduction\n",
    "    if method == \"pca\":\n",
    "        reducer = PCA(n_components=n_components, **kwargs)\n",
    "        embedding = reducer.fit_transform(X_scaled)\n",
    "        var_explained = reducer.explained_variance_ratio_\n",
    "        axis_labels = [f\"PC{i+1} ({var_explained[i]:.1%})\" for i in range(n_components)]\n",
    "        print(f\"Variance explained: {sum(var_explained):.1%}\")\n",
    "    elif method == \"umap\":\n",
    "        if not UMAP_AVAILABLE:\n",
    "            raise ImportError(\"UMAP not installed. Run: pip install umap-learn\")\n",
    "        reducer = umap.UMAP(n_components=n_components, random_state=42, **kwargs)\n",
    "        embedding = reducer.fit_transform(X_scaled)\n",
    "        axis_labels = [f\"UMAP{i+1}\" for i in range(n_components)]\n",
    "    elif method == \"tsne\":\n",
    "        if not TSNE_AVAILABLE:\n",
    "            raise ImportError(\"scikit-learn not installed for t-SNE\")\n",
    "        reducer = TSNE(n_components=n_components, random_state=42, **kwargs)\n",
    "        embedding = reducer.fit_transform(X_scaled)\n",
    "        axis_labels = [f\"t-SNE{i+1}\" for i in range(n_components)]\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown method: {method}\")\n",
    "    \n",
    "    # Create plot\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    \n",
    "    # Determine coloring\n",
    "    if color_by and color_by in df.columns:\n",
    "        color_data = df.loc[X.index, color_by]\n",
    "        \n",
    "        if color_data.dtype == 'object' or color_data.nunique() < 20:\n",
    "            # Categorical coloring\n",
    "            categories = color_data.unique()\n",
    "            colors = plt.cm.get_cmap(cmap)(np.linspace(0, 1, len(categories)))\n",
    "            color_map = dict(zip(categories, colors))\n",
    "            point_colors = [color_map[c] for c in color_data]\n",
    "            \n",
    "            scatter = ax.scatter(\n",
    "                embedding[:, 0], embedding[:, 1],\n",
    "                c=point_colors, alpha=alpha, s=point_size\n",
    "            )\n",
    "            \n",
    "            # Add legend\n",
    "            handles = [plt.scatter([], [], c=[color_map[cat]], label=cat)\n",
    "                      for cat in categories]\n",
    "            ax.legend(handles=handles, title=color_by,\n",
    "                     bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        else:\n",
    "            # Continuous coloring\n",
    "            scatter = ax.scatter(\n",
    "                embedding[:, 0], embedding[:, 1],\n",
    "                c=color_data, cmap='viridis', alpha=alpha, s=point_size\n",
    "            )\n",
    "            plt.colorbar(scatter, ax=ax, label=color_by)\n",
    "    else:\n",
    "        scatter = ax.scatter(\n",
    "            embedding[:, 0], embedding[:, 1],\n",
    "            alpha=alpha, s=point_size, c='steelblue'\n",
    "        )\n",
    "    \n",
    "    ax.set_xlabel(axis_labels[0], fontsize=12)\n",
    "    ax.set_ylabel(axis_labels[1], fontsize=12)\n",
    "    ax.set_title(f\"{method.upper()} - {len(X)} cells\", fontsize=14)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA\n",
    "fig = plot_dimensionality_reduction(data, feature_cols, method=\"pca\", color_by=CLUSTER_COL)\n",
    "\n",
    "if OUTPUT_DIR:\n",
    "    fig.savefig(f\"{OUTPUT_DIR}/pca.png\", dpi=DPI, bbox_inches='tight')\n",
    "    print(f\"Saved: {OUTPUT_DIR}/pca.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UMAP (if available)\n",
    "if UMAP_AVAILABLE:\n",
    "    fig = plot_dimensionality_reduction(\n",
    "        data, feature_cols, method=\"umap\", color_by=CLUSTER_COL,\n",
    "        n_neighbors=15, min_dist=0.1\n",
    "    )\n",
    "    \n",
    "    if OUTPUT_DIR:\n",
    "        fig.savefig(f\"{OUTPUT_DIR}/umap.png\", dpi=DPI, bbox_inches='tight')\n",
    "        print(f\"Saved: {OUTPUT_DIR}/umap.png\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"UMAP not available. Install with: pip install umap-learn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t-SNE (optional - can be slow for large datasets)\n",
    "# Uncomment to run\n",
    "\n",
    "# if len(data) <= 5000:  # t-SNE is slow, limit cells\n",
    "#     fig = plot_dimensionality_reduction(\n",
    "#         data, feature_cols, method=\"tsne\", color_by=CLUSTER_COL,\n",
    "#         perplexity=30\n",
    "#     )\n",
    "#     if OUTPUT_DIR:\n",
    "#         fig.savefig(f\"{OUTPUT_DIR}/tsne.png\", dpi=DPI, bbox_inches='tight')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Spatial Scatter Plot\n",
    "\n",
    "Visualize cells in their spatial coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_spatial_scatter(\n",
    "    df: pd.DataFrame,\n",
    "    x_col: str,\n",
    "    y_col: str,\n",
    "    color_by: Optional[str] = None,\n",
    "    figsize: tuple = (10, 10),\n",
    "    cmap: str = \"tab20\",\n",
    "    alpha: float = 0.7,\n",
    "    point_size: int = 20,\n",
    ") -> plt.Figure:\n",
    "    \"\"\"Plot spatial scatter of cells.\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    \n",
    "    if color_by and color_by in df.columns:\n",
    "        color_data = df[color_by]\n",
    "        \n",
    "        if color_data.dtype == 'object' or color_data.nunique() < 20:\n",
    "            # Categorical\n",
    "            categories = color_data.unique()\n",
    "            colors = plt.cm.get_cmap(cmap)(np.linspace(0, 1, len(categories)))\n",
    "            color_map = dict(zip(categories, colors))\n",
    "            point_colors = [color_map[c] for c in color_data]\n",
    "            \n",
    "            scatter = ax.scatter(\n",
    "                df[x_col], df[y_col],\n",
    "                c=point_colors, alpha=alpha, s=point_size\n",
    "            )\n",
    "            \n",
    "            handles = [plt.scatter([], [], c=[color_map[cat]], label=cat)\n",
    "                      for cat in categories]\n",
    "            ax.legend(handles=handles, title=color_by,\n",
    "                     bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        else:\n",
    "            # Continuous\n",
    "            scatter = ax.scatter(\n",
    "                df[x_col], df[y_col],\n",
    "                c=color_data, cmap='viridis', alpha=alpha, s=point_size\n",
    "            )\n",
    "            plt.colorbar(scatter, ax=ax, label=color_by)\n",
    "    else:\n",
    "        scatter = ax.scatter(\n",
    "            df[x_col], df[y_col],\n",
    "            alpha=alpha, s=point_size, c='steelblue'\n",
    "        )\n",
    "    \n",
    "    ax.set_xlabel(x_col, fontsize=12)\n",
    "    ax.set_ylabel(y_col, fontsize=12)\n",
    "    ax.set_title(f\"Spatial Distribution ({len(df)} cells)\", fontsize=14)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.invert_yaxis()  # Common for image coordinates\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if X_COORD_COL and Y_COORD_COL:\n",
    "    fig = plot_spatial_scatter(data, X_COORD_COL, Y_COORD_COL, color_by=CLUSTER_COL)\n",
    "    \n",
    "    if OUTPUT_DIR:\n",
    "        fig.savefig(f\"{OUTPUT_DIR}/spatial_scatter.png\", dpi=DPI, bbox_inches='tight')\n",
    "        print(f\"Saved: {OUTPUT_DIR}/spatial_scatter.png\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No spatial columns available. Set X_COORD_COL and Y_COORD_COL in configuration.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 10. Feature Comparison Scatter Plot\n",
    "\n",
    "Compare two features against each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_comparison(\n",
    "    df: pd.DataFrame,\n",
    "    x_feature: str,\n",
    "    y_feature: str,\n",
    "    color_by: Optional[str] = None,\n",
    "    figsize: tuple = (8, 8),\n",
    "    alpha: float = 0.5,\n",
    "    point_size: int = 10,\n",
    ") -> plt.Figure:\n",
    "    \"\"\"Create scatter plot comparing two features.\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    \n",
    "    if color_by and color_by in df.columns:\n",
    "        scatter = ax.scatter(\n",
    "            df[x_feature], df[y_feature],\n",
    "            c=df[color_by], cmap='viridis',\n",
    "            alpha=alpha, s=point_size\n",
    "        )\n",
    "        plt.colorbar(scatter, ax=ax, label=color_by)\n",
    "    else:\n",
    "        ax.scatter(\n",
    "            df[x_feature], df[y_feature],\n",
    "            alpha=alpha, s=point_size, c='steelblue'\n",
    "        )\n",
    "    \n",
    "    ax.set_xlabel(x_feature, fontsize=12)\n",
    "    ax.set_ylabel(y_feature, fontsize=12)\n",
    "    ax.set_title(f\"{x_feature} vs {y_feature}\", fontsize=14)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the first two features (modify as needed)\n",
    "if len(feature_cols) >= 2:\n",
    "    fig = plot_feature_comparison(data, feature_cols[0], feature_cols[1], color_by=CLUSTER_COL)\n",
    "    \n",
    "    if OUTPUT_DIR:\n",
    "        fig.savefig(f\"{OUTPUT_DIR}/feature_comparison.png\", dpi=DPI, bbox_inches='tight')\n",
    "        print(f\"Saved: {OUTPUT_DIR}/feature_comparison.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 11. Cluster Summary (if cluster column available)\n",
    "\n",
    "Comprehensive visualization of cluster assignments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cluster_summary(\n",
    "    df: pd.DataFrame,\n",
    "    cluster_col: str,\n",
    "    features: List[str],\n",
    "    figsize: tuple = (14, 10),\n",
    ") -> plt.Figure:\n",
    "    \"\"\"Create summary visualization for cluster analysis.\"\"\"\n",
    "    features = features[:10]\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=figsize)\n",
    "    \n",
    "    # 1. Cluster sizes (bar plot)\n",
    "    ax1 = axes[0, 0]\n",
    "    cluster_counts = df[cluster_col].value_counts().sort_index()\n",
    "    cluster_counts.plot(kind='bar', ax=ax1, color='steelblue', edgecolor='black')\n",
    "    ax1.set_xlabel(\"Cluster\", fontsize=10)\n",
    "    ax1.set_ylabel(\"Cell Count\", fontsize=10)\n",
    "    ax1.set_title(\"Cluster Sizes\", fontsize=12)\n",
    "    ax1.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # 2. Cluster proportions (pie chart)\n",
    "    ax2 = axes[0, 1]\n",
    "    cluster_counts.plot(\n",
    "        kind='pie', ax=ax2, autopct='%1.1f%%',\n",
    "        startangle=90, labels=None\n",
    "    )\n",
    "    ax2.set_ylabel(\"\")\n",
    "    ax2.set_title(\"Cluster Proportions\", fontsize=12)\n",
    "    ax2.legend(cluster_counts.index, loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    \n",
    "    # 3. Mean feature expression by cluster (heatmap)\n",
    "    ax3 = axes[1, 0]\n",
    "    cluster_means = df.groupby(cluster_col)[features].mean()\n",
    "    \n",
    "    # Z-score normalize\n",
    "    cluster_means_z = (cluster_means - cluster_means.mean()) / cluster_means.std()\n",
    "    \n",
    "    sns.heatmap(\n",
    "        cluster_means_z.T, ax=ax3, cmap='RdBu_r', center=0,\n",
    "        xticklabels=True, yticklabels=True,\n",
    "        cbar_kws={'label': 'Z-score'}\n",
    "    )\n",
    "    ax3.set_xlabel(\"Cluster\", fontsize=10)\n",
    "    ax3.set_ylabel(\"Feature\", fontsize=10)\n",
    "    ax3.set_title(\"Mean Feature Expression (Z-scored)\", fontsize=12)\n",
    "    plt.setp(ax3.get_xticklabels(), rotation=45, ha='right', fontsize=8)\n",
    "    plt.setp(ax3.get_yticklabels(), fontsize=8)\n",
    "    \n",
    "    # 4. Feature boxplots by cluster (for top feature by variance)\n",
    "    ax4 = axes[1, 1]\n",
    "    top_feature = df[features].var().idxmax()\n",
    "    sns.boxplot(data=df, x=cluster_col, y=top_feature, ax=ax4)\n",
    "    ax4.set_xlabel(\"Cluster\", fontsize=10)\n",
    "    ax4.set_ylabel(top_feature, fontsize=10)\n",
    "    ax4.set_title(f\"Distribution of {top_feature} by Cluster\", fontsize=12)\n",
    "    ax4.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    plt.suptitle(f\"Cluster Summary (n={len(df)} cells)\", fontsize=14, y=1.02)\n",
    "    plt.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CLUSTER_COL and CLUSTER_COL in data.columns:\n",
    "    fig = plot_cluster_summary(data, CLUSTER_COL, feature_cols)\n",
    "    \n",
    "    if OUTPUT_DIR:\n",
    "        fig.savefig(f\"{OUTPUT_DIR}/cluster_summary.png\", dpi=DPI, bbox_inches='tight')\n",
    "        print(f\"Saved: {OUTPUT_DIR}/cluster_summary.png\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No cluster column specified. Set CLUSTER_COL in configuration to generate this plot.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 12. Summary\n",
    "\n",
    "List all generated visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if OUTPUT_DIR:\n",
    "    output_path = Path(OUTPUT_DIR)\n",
    "    saved_files = list(output_path.glob(\"*.png\"))\n",
    "    \n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"VISUALIZATION SUMMARY\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"\\nDataset: {INPUT_CSV}\")\n",
    "    print(f\"Cells: {len(data)}\")\n",
    "    print(f\"Features: {len(feature_cols)}\")\n",
    "    print(f\"\\nSaved files ({len(saved_files)}):\")\n",
    "    for f in sorted(saved_files):\n",
    "        print(f\"  - {f.name}\")\n",
    "    print(f\"\\nOutput directory: {OUTPUT_DIR}\")\n",
    "else:\n",
    "    print(\"Plots displayed but not saved. Set OUTPUT_DIR to save plots.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
